{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tao-11-chen/-rencontre-.github.io/blob/master/GroundingDINO_with_Segment_Anything.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Combining Grounding DINO with Segment Anything (SAM) for text-based mask generation\n",
        "\n",
        "In this notebook, we're going to combine 2 very cool models - [Grounding DINO](https://huggingface.co/docs/transformers/main/en/model_doc/grounding-dino) and [SAM](https://huggingface.co/docs/transformers/en/model_doc/sam). We'll use Grounding DINO to generate bounding boxes based on text prompts, after which we can prompt SAM to generate corresponding segmentation masks for them.\n",
        "\n",
        "This is based on the popular [Grounded Segment Anything](https://github.com/IDEA-Research/Grounded-Segment-Anything) project - just with fewer lines of code as the models are now available in the Transformers library. Refer to the [paper](https://arxiv.org/abs/2401.14159) for details.\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/model_doc/grounded_sam.png\"\n",
        "alt=\"drawing\" width=\"900\"/>\n",
        "\n",
        "<small> Grounded SAM overview. Taken from the <a href=\"https://github.com/IDEA-Research/Grounded-Segment-Anything\">original repository</a>. </small>\n",
        "\n",
        "Author of this notebook: [Eduardo Pacheco](https://huggingface.co/EduardoPacheco) - give him a follow on Hugging\n",
        " Face!\n",
        "\n",
        "## Set-up environment\n",
        "\n",
        "Let's start by installing ðŸ¤— Transformers from source since Grounding DINO is brand new at the time of writing."
      ],
      "metadata": {
        "id": "Wgj3tUoobAlj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install --upgrade -q git+https://github.com/huggingface/transformers"
      ],
      "metadata": {
        "id": "78i_LKhJYz8M"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports\n",
        "\n",
        "Let's start by importing the required libraries."
      ],
      "metadata": {
        "id": "7r9dNrDHy2tA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, List, Dict, Optional, Union, Tuple\n",
        "\n",
        "import cv2\n",
        "import torch\n",
        "import requests\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import plotly.express as px\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "from transformers import AutoModelForMaskGeneration, AutoProcessor, pipeline"
      ],
      "metadata": {
        "id": "Y2vA9eeacmIc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Result Utils\n",
        "\n",
        "We'll store the detection results of Grounding DINO in a dedicated Python dataclass."
      ],
      "metadata": {
        "id": "A1NxJzCNrnjH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class BoundingBox:\n",
        "    xmin: int\n",
        "    ymin: int\n",
        "    xmax: int\n",
        "    ymax: int\n",
        "\n",
        "    @property\n",
        "    def xyxy(self) -> List[float]:\n",
        "        return [self.xmin, self.ymin, self.xmax, self.ymax]\n",
        "\n",
        "@dataclass\n",
        "class DetectionResult:\n",
        "    score: float\n",
        "    label: str\n",
        "    box: BoundingBox\n",
        "    mask: Optional[np.array] = None\n",
        "\n",
        "    @classmethod\n",
        "    def from_dict(cls, detection_dict: Dict) -> 'DetectionResult':\n",
        "        return cls(score=detection_dict['score'],\n",
        "                   label=detection_dict['label'],\n",
        "                   box=BoundingBox(xmin=detection_dict['box']['xmin'],\n",
        "                                   ymin=detection_dict['box']['ymin'],\n",
        "                                   xmax=detection_dict['box']['xmax'],\n",
        "                                   ymax=detection_dict['box']['ymax']))"
      ],
      "metadata": {
        "id": "ZgeXiUwIrpqJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot Utils\n",
        "\n",
        "Below, some utility functions are defined as we'll draw the detection results of Grounding DINO on top of the image."
      ],
      "metadata": {
        "id": "uCzSUQL5lAvE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def annotate(image: Union[Image.Image, np.ndarray], detection_results: List[DetectionResult]) -> np.ndarray:\n",
        "    # Convert PIL Image to OpenCV format\n",
        "    image_cv2 = np.array(image) if isinstance(image, Image.Image) else image\n",
        "    image_cv2 = cv2.cvtColor(image_cv2, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    # Iterate over detections and add bounding boxes and masks\n",
        "    for detection in detection_results:\n",
        "        label = detection.label\n",
        "        score = detection.score\n",
        "        box = detection.box\n",
        "        mask = detection.mask\n",
        "\n",
        "        # Sample a random color for each detection\n",
        "        color = np.random.randint(0, 256, size=3)\n",
        "\n",
        "        # Draw bounding box\n",
        "        cv2.rectangle(image_cv2, (box.xmin, box.ymin), (box.xmax, box.ymax), color.tolist(), 2)\n",
        "        cv2.putText(image_cv2, f'{label}: {score:.2f}', (box.xmin, box.ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color.tolist(), 2)\n",
        "\n",
        "        # If mask is available, apply it\n",
        "        if mask is not None:\n",
        "            # Convert mask to uint8\n",
        "            mask_uint8 = (mask * 255).astype(np.uint8)\n",
        "            contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "            cv2.drawContours(image_cv2, contours, -1, color.tolist(), 2)\n",
        "\n",
        "    return cv2.cvtColor(image_cv2, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "def plot_detections(\n",
        "    image: Union[Image.Image, np.ndarray],\n",
        "    detections: List[DetectionResult],\n",
        "    save_name: Optional[str] = None\n",
        ") -> None:\n",
        "    annotated_image = annotate(image, detections)\n",
        "    plt.imshow(annotated_image)\n",
        "    plt.axis('off')\n",
        "    if save_name:\n",
        "        plt.savefig(save_name, bbox_inches='tight')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Zah3Esewo4P6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_named_css_colors(num_colors: int) -> List[str]:\n",
        "    \"\"\"\n",
        "    Returns a list of randomly selected named CSS colors.\n",
        "\n",
        "    Args:\n",
        "    - num_colors (int): Number of random colors to generate.\n",
        "\n",
        "    Returns:\n",
        "    - list: List of randomly selected named CSS colors.\n",
        "    \"\"\"\n",
        "    # List of named CSS colors\n",
        "    named_css_colors = [\n",
        "        'aliceblue', 'antiquewhite', 'aqua', 'aquamarine', 'azure', 'beige', 'bisque', 'black', 'blanchedalmond',\n",
        "        'blue', 'blueviolet', 'brown', 'burlywood', 'cadetblue', 'chartreuse', 'chocolate', 'coral', 'cornflowerblue',\n",
        "        'cornsilk', 'crimson', 'cyan', 'darkblue', 'darkcyan', 'darkgoldenrod', 'darkgray', 'darkgreen', 'darkgrey',\n",
        "        'darkkhaki', 'darkmagenta', 'darkolivegreen', 'darkorange', 'darkorchid', 'darkred', 'darksalmon', 'darkseagreen',\n",
        "        'darkslateblue', 'darkslategray', 'darkslategrey', 'darkturquoise', 'darkviolet', 'deeppink', 'deepskyblue',\n",
        "        'dimgray', 'dimgrey', 'dodgerblue', 'firebrick', 'floralwhite', 'forestgreen', 'fuchsia', 'gainsboro', 'ghostwhite',\n",
        "        'gold', 'goldenrod', 'gray', 'green', 'greenyellow', 'grey', 'honeydew', 'hotpink', 'indianred', 'indigo', 'ivory',\n",
        "        'khaki', 'lavender', 'lavenderblush', 'lawngreen', 'lemonchiffon', 'lightblue', 'lightcoral', 'lightcyan', 'lightgoldenrodyellow',\n",
        "        'lightgray', 'lightgreen', 'lightgrey', 'lightpink', 'lightsalmon', 'lightseagreen', 'lightskyblue', 'lightslategray',\n",
        "        'lightslategrey', 'lightsteelblue', 'lightyellow', 'lime', 'limegreen', 'linen', 'magenta', 'maroon', 'mediumaquamarine',\n",
        "        'mediumblue', 'mediumorchid', 'mediumpurple', 'mediumseagreen', 'mediumslateblue', 'mediumspringgreen', 'mediumturquoise',\n",
        "        'mediumvioletred', 'midnightblue', 'mintcream', 'mistyrose', 'moccasin', 'navajowhite', 'navy', 'oldlace', 'olive',\n",
        "        'olivedrab', 'orange', 'orangered', 'orchid', 'palegoldenrod', 'palegreen', 'paleturquoise', 'palevioletred', 'papayawhip',\n",
        "        'peachpuff', 'peru', 'pink', 'plum', 'powderblue', 'purple', 'rebeccapurple', 'red', 'rosybrown', 'royalblue', 'saddlebrown',\n",
        "        'salmon', 'sandybrown', 'seagreen', 'seashell', 'sienna', 'silver', 'skyblue', 'slateblue', 'slategray', 'slategrey',\n",
        "        'snow', 'springgreen', 'steelblue', 'tan', 'teal', 'thistle', 'tomato', 'turquoise', 'violet', 'wheat', 'white',\n",
        "        'whitesmoke', 'yellow', 'yellowgreen'\n",
        "    ]\n",
        "\n",
        "    # Sample random named CSS colors\n",
        "    return random.sample(named_css_colors, min(num_colors, len(named_css_colors)))\n",
        "\n",
        "def plot_detections_plotly(\n",
        "    image: np.ndarray,\n",
        "    detections: List[DetectionResult],\n",
        "    class_colors: Optional[Dict[str, str]] = None\n",
        ") -> None:\n",
        "    # If class_colors is not provided, generate random colors for each class\n",
        "    if class_colors is None:\n",
        "        num_detections = len(detections)\n",
        "        colors = random_named_css_colors(num_detections)\n",
        "        class_colors = {}\n",
        "        for i in range(num_detections):\n",
        "            class_colors[i] = colors[i]\n",
        "\n",
        "\n",
        "    fig = px.imshow(image)\n",
        "\n",
        "    # Add bounding boxes\n",
        "    shapes = []\n",
        "    annotations = []\n",
        "    for idx, detection in enumerate(detections):\n",
        "        label = detection.label\n",
        "        box = detection.box\n",
        "        score = detection.score\n",
        "        mask = detection.mask\n",
        "\n",
        "        polygon = mask_to_polygon(mask)\n",
        "\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=[point[0] for point in polygon] + [polygon[0][0]],\n",
        "            y=[point[1] for point in polygon] + [polygon[0][1]],\n",
        "            mode='lines',\n",
        "            line=dict(color=class_colors[idx], width=2),\n",
        "            fill='toself',\n",
        "            name=f\"{label}: {score:.2f}\"\n",
        "        ))\n",
        "\n",
        "        xmin, ymin, xmax, ymax = box.xyxy\n",
        "        shape = [\n",
        "            dict(\n",
        "                type=\"rect\",\n",
        "                xref=\"x\", yref=\"y\",\n",
        "                x0=xmin, y0=ymin,\n",
        "                x1=xmax, y1=ymax,\n",
        "                line=dict(color=class_colors[idx])\n",
        "            )\n",
        "        ]\n",
        "        annotation = [\n",
        "            dict(\n",
        "                x=(xmin+xmax) // 2, y=(ymin+ymax) // 2,\n",
        "                xref=\"x\", yref=\"y\",\n",
        "                text=f\"{label}: {score:.2f}\",\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        shapes.append(shape)\n",
        "        annotations.append(annotation)\n",
        "\n",
        "    # Update layout\n",
        "    button_shapes = [dict(label=\"None\",method=\"relayout\",args=[\"shapes\", []])]\n",
        "    button_shapes = button_shapes + [\n",
        "        dict(label=f\"Detection {idx+1}\",method=\"relayout\",args=[\"shapes\", shape]) for idx, shape in enumerate(shapes)\n",
        "    ]\n",
        "    button_shapes = button_shapes + [dict(label=\"All\", method=\"relayout\", args=[\"shapes\", sum(shapes, [])])]\n",
        "\n",
        "    fig.update_layout(\n",
        "        xaxis=dict(visible=False),\n",
        "        yaxis=dict(visible=False),\n",
        "        # margin=dict(l=0, r=0, t=0, b=0),\n",
        "        showlegend=True,\n",
        "        updatemenus=[\n",
        "            dict(\n",
        "                type=\"buttons\",\n",
        "                direction=\"up\",\n",
        "                buttons=button_shapes\n",
        "            )\n",
        "        ],\n",
        "        legend=dict(\n",
        "            orientation=\"h\",\n",
        "            yanchor=\"bottom\",\n",
        "            y=1.02,\n",
        "            xanchor=\"right\",\n",
        "            x=1\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Show plot\n",
        "    fig.show()\n"
      ],
      "metadata": {
        "id": "Wzjx3MLPjyW8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils"
      ],
      "metadata": {
        "id": "A856bC-Nha45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mask_to_polygon(mask: np.ndarray) -> List[List[int]]:\n",
        "    # Find contours in the binary mask\n",
        "    contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Find the contour with the largest area\n",
        "    largest_contour = max(contours, key=cv2.contourArea)\n",
        "\n",
        "    # Extract the vertices of the contour\n",
        "    polygon = largest_contour.reshape(-1, 2).tolist()\n",
        "\n",
        "    return polygon\n",
        "\n",
        "def polygon_to_mask(polygon: List[Tuple[int, int]], image_shape: Tuple[int, int]) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Convert a polygon to a segmentation mask.\n",
        "\n",
        "    Args:\n",
        "    - polygon (list): List of (x, y) coordinates representing the vertices of the polygon.\n",
        "    - image_shape (tuple): Shape of the image (height, width) for the mask.\n",
        "\n",
        "    Returns:\n",
        "    - np.ndarray: Segmentation mask with the polygon filled.\n",
        "    \"\"\"\n",
        "    # Create an empty mask\n",
        "    mask = np.zeros(image_shape, dtype=np.uint8)\n",
        "\n",
        "    # Convert polygon to an array of points\n",
        "    pts = np.array(polygon, dtype=np.int32)\n",
        "\n",
        "    # Fill the polygon with white color (255)\n",
        "    cv2.fillPoly(mask, [pts], color=(255,))\n",
        "\n",
        "    return mask\n",
        "\n",
        "def load_image(image_str: str) -> Image.Image:\n",
        "    if image_str.startswith(\"http\"):\n",
        "        print('yes')\n",
        "        image = Image.open(requests.get(image_str, stream=True).raw).convert(\"RGB\")\n",
        "    else:\n",
        "        image = Image.open(image_str).convert(\"RGB\")\n",
        "\n",
        "    return image\n",
        "\n",
        "def get_boxes(results: DetectionResult) -> List[List[List[float]]]:\n",
        "    boxes = []\n",
        "    for result in results:\n",
        "        xyxy = result.box.xyxy\n",
        "        boxes.append(xyxy)\n",
        "\n",
        "    return [boxes]\n",
        "\n",
        "def refine_masks(masks: torch.BoolTensor, polygon_refinement: bool = False) -> List[np.ndarray]:\n",
        "    masks = masks.cpu().float()\n",
        "    masks = masks.permute(0, 2, 3, 1)\n",
        "    masks = masks.mean(axis=-1)\n",
        "    masks = (masks > 0).int()\n",
        "    masks = masks.numpy().astype(np.uint8)\n",
        "    masks = list(masks)\n",
        "\n",
        "    if polygon_refinement:\n",
        "        for idx, mask in enumerate(masks):\n",
        "            shape = mask.shape\n",
        "            polygon = mask_to_polygon(mask)\n",
        "            mask = polygon_to_mask(polygon, shape)\n",
        "            masks[idx] = mask\n",
        "\n",
        "    return masks"
      ],
      "metadata": {
        "id": "vIqTxb5LhcjU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mask_to_image(mask):\n",
        "  return Image.fromarray((mask).astype(np.uint8))"
      ],
      "metadata": {
        "id": "IvJ7ISbKY_5U"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "img_url = '/content/frame000001.jpg'\n",
        "detector_id = \"IDEA-Research/grounding-dino-tiny\"\n",
        "segmenter_id = \"facebook/sam-vit-base\"\n",
        "object_detector = pipeline(model=detector_id, task=\"zero-shot-object-detection\", device='cuda')\n",
        "segmentator = AutoModelForMaskGeneration.from_pretrained(segmenter_id).to('cuda')\n",
        "processor = AutoProcessor.from_pretrained(segmenter_id)\n",
        "\n",
        "img = load_image(img_url)\n",
        "labels = ['apple.']\n",
        "detection_results = object_detector(img, candidate_labels=labels, threshold=0.3)\n",
        "detection_results = [DetectionResult.from_dict(result) for result in detection_results]\n",
        "\n",
        "boxes = get_boxes(detection_results)\n",
        "inputs = processor(images=img, input_boxes=boxes, return_tensors=\"pt\").to('cuda')\n",
        "outputs = segmentator(**inputs)\n",
        "masks = processor.post_process_masks(\n",
        "        masks=outputs.pred_masks,\n",
        "        original_sizes=inputs.original_sizes,\n",
        "        reshaped_input_sizes=inputs.reshaped_input_sizes\n",
        ")[0]\n",
        "\n",
        "masks = refine_masks(masks, True)\n",
        "\n",
        "\n",
        "mask_img = mask_to_image(masks[0])\n",
        "filename = '/content/mask.jpg'\n",
        "mask_img.save(filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "865OqJGeW15S",
        "outputId": "27a12564-f6c2-44c9-feeb-9ba189ef86e8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Device set to use cuda\n"
          ]
        }
      ]
    }
  ]
}